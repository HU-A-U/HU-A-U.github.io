<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[nginx+uwsgi+flask/django部署web服务]]></title>
    <url>%2F2019%2F06%2F18%2Fnginx-uwsgi-flask-django%E9%83%A8%E7%BD%B2web%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[概述使用nginx+uwsgi+flask 部署web服务 一、放置项目文件将项目文件夹放到服务器上 1.ssh 远程连接服务器,登陆密码 JYcxys@30301ssh python@192.168.1.150 2.使用 scp 将本地项目文件放到服务器上的 /home/python/workspace 工作目录下1scp -r /Users/hu-a-u/MyCode/work/yct_worker python@192.168.1.150:/home/python/workspace 如果是文件夹需要带上 -r 参数 二、编写uwsgi的.ini文件（一般需要sudo）.ini 文件用于运行服务，在服务器的 /etc/nginx 目录下创建一个ini文件1sudo nano demo.ini 内容如下：1234567891011121314[uwsgi]chdir = /home/python/workspace/demo #项目文件夹wsgi-file = /home/python/workspace/demo/manage.py #项目启动py文件home = /home/python/.virtualenvs/py3_flask/ #项目运行的虚拟环境master = trueprocesses = 2socket = 127.0.0.1:5002 #运行在一个端口vacuum = trueenable-threads = truebuffer-size = 65536daemonize = %(chdir)/uwsgi.log #uwsig的日志文件stats=%(chdir)/export_flask_uwsgi_out.status #运行状态文件pidfile=%(chdir)/export_flask_uwsgi_out.pid #记录运行的进程号，便于重启uwsgi服务callable = app chdir 是项目的文件夹路径 wsgi-file 是项目运行的py文件 home 是项目运行的环境依赖，虚拟环境 socket 运行在服务器地址 daemonize 记录日志 callable 指出的是具体执行.run方法的那个实体的名字，一般而言都是’app=Flask(name)’所以这里是app 三、启动uwsgi1uwsgi --ini /etc/nginx/demo.ini 一般不需要加sudo，启动后监听端口5002是否已经在运行，使用 netstat -lntp 命令123python@python-splinter:/$ netstat -lntpProto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 127.0.0.1:5002 0.0.0.0:* LISTEN 3603/uwsgi 四、配置nginx并启动nginx的配置在 /etc/nginx/sites-available切换到目录下，sudo创建一个文件没有后缀 1sudo nano demo 配置内容如下:12345678910111213141516server &#123; listen 6600 ; //默认的web访问端口 listen [::]:6600 ; server_name 116.228.88.888; //对外访问的地址，也可以是域名 index index.html index.htm index.nginx-debian.html; location /static &#123; alias /home/python/workspace/demo/static; //静态文件的目录 &#125; location / &#123; uwsgi_pass 127.0.0.1:5002; //需要和uwsgi的配置文件里socket项的地址相同,否则无法让uwsgi接收到请求。 include /etc/nginx/uwsgi_params; //这里是导入的uwsgi配置 &#125;&#125; 文件创建完成之后，创建软链到 /etc/nginx/sites-enabled 目录下，命令ln -s [源文件全路径] [目标文件全路径]1ln -s /etc/nginx/sites-available/demo /etc/nginx/sites-enabled/demo 这样配置完后，需要重启nginx服务1sudo nginx -s reload 当外部有一个6600端口的请求送到本机时，先让nginx开始处理。nginx进行一些处理之后转发给这里配置的uwsgi_pass地址，刚好传送给uwsgi处理。再由uwsgi来调用项目中的代码处理请求返回。 五、注意服务都运行正常后，用浏览器访问不了，检查防火墙是否开启6600这个端口 查看防火墙状态12python@python-splinter:/$ sudo firewall-cmd --staterunning 说明防火墙已开启 查看已开放的端口12python@python-splinter:/$ sudo firewall-cmd --list-ports5000/tcp 5002/tcp 5500/tcp 5005/tcp 5006/tcp 8000/tcp 5008/tcp 12233/tcp 可以看到没有6600端口，然后防火墙开启6600端口12python@python-splinter:/$ sudo firewall-cmd --zone=public --add-port=6600/tcp --permanentsuccess 开启成功后需要重启防火墙12python@python-splinter:/$ sudo firewall-cmd --reloadsuccess 然后使用浏览器访问成功]]></content>
      <categories>
        <category>nginx</category>
        <category>uwsgi</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>uwsgi</tag>
        <tag>flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pyautogui控制鼠标键盘]]></title>
    <url>%2F2019%2F06%2F18%2Fpyautogui%E6%8E%A7%E5%88%B6%E9%BC%A0%E6%A0%87%E9%94%AE%E7%9B%98%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[celery开启flower后台监控任务执行状态(docker)]]></title>
    <url>%2F2019%2F06%2F17%2Fcelery%E5%BC%80%E5%90%AFflower%E5%90%8E%E5%8F%B0%E7%9B%91%E6%8E%A7%E4%BB%BB%E5%8A%A1%E6%89%A7%E8%A1%8C%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[使用flower容器进行worker后台监控使用容器，部署在192.168.1.230 监听本地worker的容器名称 yct_flower,内网访问地址 192.168.1.230:5555 监听阿里云worker的容器名称 aliyun01_flower,内网访问地址 192.168.1.230:5559 文件夹目录下只有三个有用文件12345.├── Dockerfile├── README.md├── docker-entrypoint.sh└── requirements.txt Dockerfile1234567891011121314151617FROM python:3.7ADD requirements.txt /tmp/requirements.txtRUN pip install -r /tmp/requirements.txtRUN mkdir /codeWORKDIR /codeCOPY . /codeCOPY docker-entrypoint.sh docker-entrypoint.shRUN chmod +x docker-entrypoint.shRUN apt-get install libfontconfigENV BROKER_HOST 47.102.218.137ENV BROKER_PORT 5672ENV VIRTUAL_HOST 'yct'EXPOSE 5555CMD /code/docker-entrypoint.sh docker-entrypoint.sh启动文件123#!/bin/shset -ecelery flower --broker=amqp://cic_admin:JYcxys@3030@$BROKER_HOST:$BROKER_PORT/$VIRTUAL_HOST requirements.txt12celery==4.3.0rc1flower==0.9.3 启动命令12docker run --env BROKER_HOST=47.102.218.137 --env BROKER_PORT=5672 --env VIRTUAL_HOST='yct' --name flower -p 5555:5555 -d [镜像名称]docker run --env BROKER_HOST=47.102.218.137 --env BROKER_PORT=5672 --env VIRTUAL_HOST='newproxy-yuanqu01' --name flower -p 5559:5555 -d [镜像名称] 其中 BROKER_HOST 、BROKER_PORT 和 VIRTUAL_HOST 为环境变量 BROKER_HOST 、BROKER_PORT 指定消息队列地址和端口 VIRTUAL_HOST 指定消息队列的的 vhost名称 镜像地址（此处是我自己的镜像地址，后面可以自己打包）daocloud.io/huhuhuhu/flower_docker:latest 当监控下的任务太多时，重启flower容器，将前面的任务记录清空1docker restart yct_flower]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>celery</tag>
        <tag>flower</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yct_proxy和yct_worker的部署地址]]></title>
    <url>%2F2019%2F06%2F17%2Fyct-proxy%E5%92%8Cyct-worker%E7%9A%84%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[代码地址yct_proxy代码:https://github.com/HU-A-U/my-proxy yct_worker代码:https://github.com/HU-A-U/yct_worker 分支 aliyun 是 部署在阿里云上的服务的代码内容，不需要合并 阿里云RabbitMQ后台管理地址http://47.102.218.137:15672 用户名：cic_admin 密码：JYcxys@3030 本地服务器 cic-odoo服务器地址1ssh root@192.168.1.230 镜像地址（此处为我自己的打包好的镜像地址，最好后面自己重新打包镜像，重新部署一遍）本地服务proxy镜像地址 daocloud.io/huhuhuhu/new_proxy:latest 本地服务worker镜像地址 运行的容器名称redis容器，yct_redis,做数据缓存 proxy容器，yct_proxy,做代理服务 worker容器，worker_c 做数据缓存到redis中，worker_a 做数据解析 ，worker_s 做数据存库到mysql aliyun_worker容器，to_save 处理阿里云代理的数据存到本地数据库 连接RabbitMQ的地址 yct123RABBITMQ_HOST = '47.102.218.137'RABBITMQ_PORT = 5672BROKER_URL = 'amqp://cic_admin:JYcxys@3030@&#123;&#125;:&#123;&#125;/yct'.format(RABBITMQ_HOST,RABBITMQ_PORT) 123456bee85252f246 daocloud.io/huhuhuhu/new_proxy:latest "/bin/sh -c /code/..." 5 hours ago Up 5 hours 0.0.0.0:8888-&gt;8080/tcp yct_proxy30a27b1a1504 daocloud.io/huhuhuhu/yct_worker:latest "/bin/sh -c /code/..." 2 days ago Up 2 days worker_sfeff1b804441 daocloud.io/huhuhuhu/yct_worker:latest "/bin/sh -c /code/..." 2 days ago Up 2 days worker_a937bda5c14b7 daocloud.io/huhuhuhu/yct_worker:latest "/bin/sh -c /code/..." 2 days ago Up 2 days worker_cb461871a137b docker.io/redis "docker-entrypoint..." 2 weeks ago Up 2 weeks 6379/tcp yct_redis666ead4ef827 daocloud.io/huhuhuhu/aliyun_yct_worker:latest "/bin/sh -c /code/..." 4 days ago Up 4 days to_save 阿里云服务器 newprocy-yuanqu01部署容器地址1ssh root@47.103.197.163 运行容器名称redis容器，yct_redis,做数据缓存 proxy容器，yct_proxy,做代理服务 worker容器，to_create 做数据缓存到redis中，to_analysis 做数据解析解析出需要的字段，将解析后的数据作为参数传递到to_save消息队列，供本地的服务器的to_save容器存库 连接RabbitMQ的地址 newprocy-yuanqu01123RABBITMQ_HOST = '47.102.218.137'RABBITMQ_PORT = 5672BROKER_URL = 'amqp://cic_admin:JYcxys@3030@&#123;&#125;:&#123;&#125;/newprocy-yuanqu01'.format(RABBITMQ_HOST,RABBITMQ_PORT) 1234567[root@newprocy-yuanqu01 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0cf0c9952b4b daocloud.io/huhuhuhu/yct_white_list:latest "/bin/sh -c 'nginx -…" 3 days ago Up 3 days 0.0.0.0:9999-&gt;6666/tcp white_list5251bcc0e7d6 daocloud.io/huhuhuhu/aliyun_yct_worker:latest "/bin/sh -c /code/do…" 4 days ago Up 4 days to_analysisd5542e638405 daocloud.io/huhuhuhu/aliyun_yct_worker:latest "/bin/sh -c /code/do…" 4 days ago Up 4 days to_create44f9d01fb72a daocloud.io/huhuhuhu/aliyun01_proxy:aliyun-c0ecb62 "/bin/sh -c /code/do…" 4 days ago Up 4 days 0.0.0.0:8888-&gt;8080/tcp yct_proxy15df20e8da42 redis:3.2.12 "docker-entrypoint.s…" 2 weeks ago Up 6 days 6379/tcp yct_redis]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python之上下文管理器]]></title>
    <url>%2F2019%2F05%2F29%2Fpython%E4%B9%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Docker学习之--link容器互联]]></title>
    <url>%2F2019%2F05%2F28%2FDocker%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%AE%B9%E5%99%A8%E4%BA%92%E8%81%94%2F</url>
    <content type="text"><![CDATA[概述由于业务需要，需要将现有的服务迁移到阿里云上，该服务使用容器运行，外部需要连接一个redis进行暂存数据；所以使用另一个容器运行一个redis，本文就是关于现有容器服务互联到另外一个redis容器，其他数据库mysql等也是类似的做法。 环境CentOS 7.6 下载redis镜像在 DockerHub https://hub.docker.com/_/redis1docker pull redis 运行redis镜像由于是容器之间的互联，所以就不做端口映射，redis容器默认运行在6379端口启动命令如下：1docker run --name [redis容器名称] -d [镜像名] 修改服务中的redis的连接地址修改我的已有服务配置文件中的redis地址 使用–link参数连接redis1docker run --name test_proxy --link [redis容器名称]:aliyun_redis -p 8888:8080 -d [服务镜像] 其中 –link 后面冒号左右两边分别代表 已在运行的redis容器名称或id 和 服务里的redis地址名称；直接将正在运行的redis服务映射到服务里面的redis地址.]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小记--关于mitmproxy的代理连接被重置的问题]]></title>
    <url>%2F2019%2F05%2F27%2F%E5%B0%8F%E8%AE%B0-%E5%85%B3%E4%BA%8Emitmproxy%E7%9A%84%E4%BB%A3%E7%90%86%E8%BF%9E%E6%8E%A5%E8%A2%AB%E9%87%8D%E7%BD%AE%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[概述在浏览器设置proxy的代理之后，访问网页显示连接被重置，然后查看日志，报错信息如下： 1234567[root@procy ~]# docker logs test_proxyLoading script /code/start_script.pyProxy server listening at http://*:8080172.104.123.101:58074: clientconnectClient connection from ::ffff:172.104.123.101 killed by block_global172.104.123.101:58074: Connection killed172.104.123.101:58074: clientdisconnect 可以看到 ‘killed by block_global’ 连接被kill掉 解决去官网找到解决办法 启动参数 添加 –set block_global=false 将block_global设为false 试了一下1mitmdump --set block_global=false -s /code/start_script.py -s 参数是使用启动脚本进行启动 又恢复正常，至于原因不是很清楚，因为之前一直运行很正常，可能是跟网络有关。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>mitmproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker中运行mitiproxy+celery]]></title>
    <url>%2F2019%2F05%2F24%2FDocker%E4%B8%AD%E8%BF%90%E8%A1%8Cmitiproxy-celery%2F</url>
    <content type="text"><![CDATA[概述本文只是关于在docker中运行mitmproxy和celery的过程； 需求使用mitmproxy做中间人代理获取网站的请求和响应，以及使用celery worker 对截取的请求进行过滤解析后存库 使用docker的原因1.最初的本地开发环境是Windows系统，由于celery的某些版本对Windows不支持，所以会出现不兼容的问题，最后找到celery==4.3.0rc1版本，同时安装mitmproxy和celery成功.2.当我在服务器(ubuntu16.04)上使用虚拟环境安装环境依赖的时候，安装mitmproxy一直安装失败，好像是关于系统编译的一些报错，mitmproxy只支持python3.6以上版本，查询无果，最后放弃。 使用docker最主要的就是隔离性，轻量化，版本控制，迁移比较方便 版本mitmproxy==4.0.4 celery==4.3.0rc1 编写dockerfile分别打包两个镜像，一个镜像运行proxy容器，一个镜像运行celery的worker 关于dockerfile的语法,参考https://www.cnblogs.com/lienhua34/p/5170335.html proxy镜像首先创建Dockerfile文件，没有后缀，注意文件名首字母D大写，因为踩过坑 12345678910111213FROM python:3.7 ADD requirements.txt /tmp/requirements.txtRUN pip install -r /tmp/requirements.txtRUN mkdir /codeWORKDIR /codeCOPY . /codeCOPY docker-entrypoint.sh docker-entrypoint.shRUN chmod +x docker-entrypoint.shRUN apt-get install libfontconfigEXPOSE 8080CMD /code/docker-entrypoint.sh 使用EXPOSE命令将容器的运行端口8080暴露出来使用CMD命令运行docker-entrypoint.sh启动文件，内容如下: 1/usr/local/bin/mitmdump -s /code/start_script.py 如果不加 /usr/local/bin/ 路径会找不到 mitmdump 创建镜像我使用的是daocloud平台打包镜像，比较方便，关联GitHub仓库就可以直接打包，有新的提交就会自动重新打包一个版本 执行日志打包的项目 拉取打包好的镜像1docker pull [镜像] 启动容器1celery run --name my_proxy -p 8888:8080 -d &lt;镜像名称&gt; 使用 -p 参数进行端口映射，将容器暴露的8080端口映射到宿主机的8888端口 查看运行状态,是否正常启动123[root@procy ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb5af5afc3d74 daocloud.io...:latest "/bin/sh -c /code/do…" 3 seconds ago Up 3 seconds 0.0.0.0:8888-&gt;8080/tcp my_proxy 看到status为up，并且已经映射到8888端口 查看日志,容器内部监听8080端口123[root@procy ~]# docker logs my_proxyLoading script /code/start_script.pyProxy server listening at http://*:8080 代理运行成功后设置代理在浏览器中设置代理地址，一般使用火狐，设置代理地址为服务的地址，在8888端口 随便打开一个网页，可以看到请求地址为所设置的代理地址 使用 docker logs my_proxy看到日志的输出一大堆，找到你访问的那一条URL就说明代理成功了1234180.165.231.56:57424: GET http://addons.g-fox.cn/ntab.gif?c=ntab&amp;t=timing&amp;a=1-o-idb&amp;d=73&amp;f=&amp;r=0.8194234211953002&amp;cid=firefox.com.cn &lt;&lt; 200 OK 800b180.165.231.56:57426: GET http://addons.g-fox.cn/ntab.gif?c=ntab&amp;t=timing&amp;a=1-o-cursor&amp;d=80&amp;f=&amp;r=0.9766453266846722&amp;cid=firefox.com.cn &lt;&lt; 200 OK 800b celery镜像环境依赖与proxy镜像的相同，只是运行的启动命令不同；因为这里的数据解析任务我是分为三个队列去执行，这样异步执行可以减少数据处理的时间，相互独立，失败的任务不会影响到其他的任务1.第一个队列create里的任务只是简单的将mitmproxy传递过来的原始pickle后的请求以及响应的对象暂存到redis中，并设置过期时间，然后异步调用analysis队列2.第二个队列analysis里的任务是解析pickle前的request对象和response对象，获取需要的内容，再异步调用save队列3.第三个队列save主要是将解析后的数据更新到mysql中，以供页面回显。 celery Dockerfile内容如下： 12345678910111213141516FROM python:3.7ADD requirements.txt /tmp/requirements.txtRUN pip install -r /tmp/requirements.txtRUN mkdir /codeWORKDIR /codeCOPY . /codeCOPY docker-entrypoint.sh docker-entrypoint.shRUN chmod +x docker-entrypoint.shRUN apt-get install libfontconfigENV C_QUEUE to_createENV A_QUEUE to_analysisENV S_QUEUE to_saveENV QUEUE to_createCMD /code/docker-entrypoint.sh docker-entrypoint.sh执行文件内容如下：123456789101112#!/bin/shset -eif [ "$QUEUE" = "$C_QUEUE" ]; then celery -A handle_data.celery_app worker -l info -Q to_create --uid 13elif [ "$QUEUE" = "$A_QUEUE" ]; then celery -A handle_data.celery_app worker -l info -Q to_analysis --uid 13elif [ "$QUEUE" = "$S_QUEUE" ]; then celery -A handle_data.celery_app worker -l info -Q to_save --uid 13else exit 1fi dockerfile中的 ENV 指定环境变量,通过.sh文件判断启动命令里的参数，to_create,to_analysis,to_save 三个队列，指定到不同的消息队列 启动命令是123docker run --name to_create --link yct_redis:aliyun_redis -e QUEUE=to_create -d [镜像名称]docker run --name to_analysis --link yct_redis:aliyun_redis -e QUEUE=to_analysis -d [镜像名称]docker run --name to_save --link yct_redis:aliyun_redis -e QUEUE=to_save -d [镜像名称] –name 启动容器名称 –link 是关联redis容器，作为数据缓存 -e 参数后面 指定 QUEUE 为 to_create 队列 -d 守护进程运行 启动三个容器，进行数据解析和存库 迁移到阿里云由于客户量增多，需要将服务从我们的服务器扩展到阿里云上, 由于解析后的数据需要放到自己本地的数据库里； 1.在RabbitMQ上新建一个vhost,存放阿里云代理扔出的任务消息,此处是 newproxy-yuanqu01； RabbitMQ是运行阿里云上的另一台服务器，地址为 47.102.218.137:5672 2.先运行proxy代理，关联到docker redis 容器1docker run --name yct_proxy --link yct_redis:aliyun_redis -p 8888:8080 -d [镜像名称] 3.运行celery worker，读取到rabbitMQ中的任务消息去执行,进行数据截取，解析12docker run --name to_create --link yct_redis:aliyun_redis -e QUEUE=to_create -d [镜像名称]docker run --name to_analysis --link yct_redis:aliyun_redis -e QUEUE=to_analysis -d [镜像名称] 4.由于解析后的数据是要存到我们自己的服务器数据库中，所以就要将数据存储的服务部署到自己的服务器上使用同样的yct_worker镜像，连接到阿里云的RabbitMQ，订阅to_save消息队列里的内容，将数据存储到正式环境数据库中1docker run --name to_save --link yct_redis:aliyun_redis -e QUEUE=to_save -d [镜像名称]]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>celery</tag>
        <tag>mitmproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker学习之Dockerfile]]></title>
    <url>%2F2019%2F05%2F24%2FDocker%E5%AD%A6%E4%B9%A0%E4%B9%8BDockerfile%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[工作中的环境参数(个人使用)]]></title>
    <url>%2F2019%2F04%2F20%2Fworkfile%2F</url>
    <content type="text"><![CDATA[服务器 ssh python@192.168.1.150 , JYcxys@3030 mysql地址 192.168.1.170:3306 连接串： 1"mysql+pymysql://cic_admin:TaBoq,,1234@192.168.1.170:3306/cicjust_splinter?charset=utf8&amp;autocommit=true" 192.168.10.11:3306 连接串： 1"mysql+pymysql://cic_admin:159357a@&#123;&#125;:&#123;&#125;/cic_splinter?charset=utf8&amp;autocommit=true" Mysql 远程连接 mysql -u 用户名 -p密码 -h IP地址 -P 端口号 -D 数据库名字 celery配置 12345678910111213RABBITMQ_HOST = '192.168.1.152'RABBITMQ_PORT = 5672RABBITMQ_USER = 'rabbitmq'RABBITMQ_PWD = 'JYcxys@3030'REDIS_HOST = "192.168.1.152"REDIS_PORT = 16379CELERY_BROKER_URL = 'amqp://&#123;0&#125;:&#123;1&#125;@&#123;2&#125;:&#123;3&#125;/myvhost'\ .format(RABBITMQ_USER,RABBITMQ_PWD,RABBITMQ_HOST,RABBITMQ_PORT)CELERY_RESULT_BACKEND = 'redis://&#123;0&#125;:&#123;1&#125;/15'.format(REDIS_HOST,REDIS_PORT) celery命令 1.守护进程启动方式(start/stop/restart) 1celery multi start export_for_in -A celery_tasks.celery_app -l info --logfile=./celerylog.log 2.开启flower后台监控 12celery.exe flower --broker=amqp://guest:guest@localhost:5672/testcelery.exe flower -broker=amqp://cic_admin:JYcxys@3030@192.168.1.152:5672/yct rabbitmq的安装与配置 Windows安装rabbitmq docker命令 启动chrome镜像 1sudo docker run -d --name chrome_for_yzf -p 5902:5900 -p 4442:4444 selenium/standalone-chrome-debug 下载镜像 1sudo docker pull selenium/standalone-chrome-debug 说明：standalone-chrome-debug 镜像是带有vnc server 运行容器(–name后为容器的名称,-d 守护进程运行,-p 由容器露出的8080端口,映射到宿主机的8081端口) 1docker run --name your_app_name -p 8081:8080 -d selenium/standalone-chrome-debug 使用docker MySQL 拉取mysql镜像 1docker pull daocloud.io/library/mysql 运行MySQL容器 dockers(MYSQL_ROOT_PASSWORD=后为数据库定义密码用户名为root) 1docker run --name mysql_service -e MYSQL_ROOT_PASSWORD=your_pwd -d daocloud.io/library/mysql 使用其他的docker容器连接docker的MySQL服务 1docker run --name some_app --link your_mysql_name:mysql -p 8080:8080 -d daocloud.io/library/mysql 将MySQL容器内的数据持久化到宿主机上 1docker run --name mysql --privileged=true -v /home/docker_mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=cicjust_proxy -d daocloud.io/library/mysql]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小记--阿里云pip配置虚拟环境报错]]></title>
    <url>%2F2019%2F03%2F01%2F%E5%B0%8F%E8%AE%B0--%E9%98%BF%E9%87%8C%E4%BA%91pip%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[今天在阿里云上使用pip3安装虚拟环境的时候，出现了一个错误locale.Error: unsupported locale setting 不支持语言环境，报错如下： 123456789root@iZuf6eh47kp5ew16h2mywqZ:~# sudo pip3 install virtualenvTraceback (most recent call last): File "/usr/bin/pip3", line 11, in &lt;module&gt; sys.exit(main()) File "/usr/lib/python3/dist-packages/pip/__init__.py", line 215, in main locale.setlocale(locale.LC_ALL, '') File "/usr/lib/python3.5/locale.py", line 594, in setlocale return _setlocale(category, locale)locale.Error: unsupported locale setting 解决办法很简单，设置语言就好了 12export LC_ALL=&quot;en_US.UTF-8&quot;export LC_CTYPE=&quot;en_US.UTF-8&quot; 执行上面这两句就OK了，后面就可以继续pip安装了。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下安装python3]]></title>
    <url>%2F2019%2F03%2F01%2Fubuntu%E4%B8%8Bpython3%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[概述ubuntu系统自带python2.7，不同的版本的ubuntu所带的python3的版本也有所不同，我现在使用的这台是python3.5;由于需要的服务只支持python3.6以上版本，所以本文以安装python3.7为例 服务器运行环境：ubuntu18.04 安装方式简介:不影响已有的python其他版本环境 增量式安装 完全隔离的沙箱环境 基本环境(便于后面的编译成功)中间可能有多余空格，去除下再运行，一般都能安装成功，如果不能可以先更新下sudo apt-get update 123sudo apt-get install zlib1g-dev libbz2-dev libssl-dev libncurses5-dev libsqlite3-dev libreadline-dev tk-dev libgdbm-dev libdb-dev libpcap-dev xz-utils libexpat1-dev liblzma-dev libffi-dev libc6-dev 下载在python官网下载指定平台下的python3.7.1的环境 1wget https://www.python.org/ftp/python/3.7.1/Python-3.7.1.tgz 下载完成后，所在目录下会有 Python-3.7.1.tgz 的文件 解压进行解压 1tar -xvzf Python-3.7.1.tgz 所在目录下会有 Python-3.7.1 的文件夹 安装进入文件夹Python-3.7.1,进行配置 12cd Python-3.7.1./configure --with-ssl --prefix=/usr/local/python3 编译、安装 12makemake install 执行后可能会报错，请参考https://blog.csdn.net/jpch89/article/details/81813267 删除软链先执行查看版本，如果有则证明软连接已经存在，先将其删除再重新建立 12# python3 -VPython 3.5.2 12# pip3 -VThe program 'pip3' is currently not installed. You can install it by typing:apt install python3-pip 可见我的机器上的默认的python3的版本为3.5，pip3没有安装 删除软链 12# rm -rf /usr/bin/python3# rm -rf /usr/bin/pip3 建立新的指向python3.7的软链1234#添加python3的软链接ln -s /usr/local/python3/bin/python3.7 /usr/bin/python3#添加 pip3 的软链接ln -s /usr/local/python3/bin/pip3.7 /usr/bin/pip3 查看版本12# python3 -VPython 3.7.1 12# pip3 -Vpip 10.0.1 from /usr/local/python3/lib/python3.7/site-packages/pip (python 3.7) 至此安装成功。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>
